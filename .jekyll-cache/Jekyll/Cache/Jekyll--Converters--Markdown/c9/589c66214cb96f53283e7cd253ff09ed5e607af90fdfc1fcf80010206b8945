I"`<h2 id="project-proposal-overview">Project Proposal Overview</h2>

<p>Welcome to our project proposal homepage! Below is an overview of what we’re interested in and how we plan on structuring our project, as well as some questions included at the bottom that we hope to get some advice/feedback/input on.</p>

<h3 id="background">Background</h3>

<ol>
  <li>Representation Primer
    <ul>
      <li>What is representation?</li>
      <li>Why is it important to learn well (properties of good representations and its utility)?</li>
    </ul>
  </li>
  <li>Autoencoder Primer
    <ul>
      <li>What is an autoencoder (AE) and how does it relate to representation?</li>
    </ul>
  </li>
</ol>

<h3 id="iterated-representation-learning-irl-framework">Iterated Representation Learning (IRL) Framework</h3>

<ol>
  <li>AEs (deterministic reconstruction)
    <ul>
      <li>Step 1: Given some dataset, use an AE to learn its embedding space.</li>
      <li>Step 2: Using the learned embedding and AE, reconstruct the original dataset and compute the reconstruction loss.</li>
      <li>Step 3: Using the reconstructed dataset, repeat Steps 1 and 2, iterating as long as desired.</li>
    </ul>
  </li>
  <li>VAEs (generative modeling)
    <ul>
      <li>Step 1: Given some dataset, use a VAE to learn its embedding space.</li>
      <li>Step 2: Using the learned embedding and VAE, generate a new dataset.</li>
      <li>Step 3: Using the newly generated dataset, repeat Steps 1 and 2, iterating as long as desired.</li>
    </ul>
  </li>
</ol>

<h3 id="potential-questions-and-hypotheses">Potential Questions and Hypotheses</h3>
<ol>
  <li>Following the iterated representation learning framework above, can we iterate until we reach some kind of convergence with respect to the model and/or learned embedding space?
    <ul>
      <li>If so, can this tell us any properties of the representation space, learned representation, model, and/or data?</li>
      <li>Does the number of iterations until convergence have anything to do with how “good” or stable the model or learned representation is?</li>
    </ul>
  </li>
  <li>In the deterministic autoencoder case, how do the reconstruction losses perform as iterations go on? Do we converge? How quickly? If the loss seems to diverge (relative to the original data), does it diverge linearly, exponentially, etc.?</li>
  <li>What can we say about characteristics of the data that are maintained through iterations, and characteristics that evolve as the iterations go on?
    <ul>
      <li>For example, if we observe that a model remains invariant to a certain feature, but becomes sensitive to new features of the data, what does this tell us about these particular features, our model, and the original data itself?</li>
      <li>Are there any other patterns we can identify along these lines?</li>
    </ul>
  </li>
  <li>Can we propose some sort of representation learning evaluation framework using iterated representation learning, e.g. rough guidelines on ideal number of iterations required until convergence, and what this says about how good a model is?</li>
</ol>

<h3 id="future-work">Future Work</h3>
<ol>
  <li>How can we make iterated representation learning more computationally tractable?</li>
  <li>Can any of these results be generalized to other types of deep learning models?</li>
  <li>Are there any theoretical guarantees we can prove?</li>
</ol>

<h2 id="references-and-resources">References and Resources</h2>

<h3 id="possible-data-sources">Possible Data Sources:</h3>
<ul>
  <li>MNIST, FashionMNIST,</li>
  <li>CIFAR-10, CIFAR-100</li>
  <li>Pytorch’s Food101 dataset, CelebA dataset</li>
  <li>Tensorflow’s cats_vs_dogs dataset</li>
</ul>

<h3 id="possible-references">Possible References:</h3>
<ul>
  <li>Robustness of Unsupervised Learning Without Labels (Petrov and Kwiatkowska, 2022)</li>
  <li>Understanding Robust Learning through the Lens of Representation Similarities (Cianfarani et al., 2022)</li>
  <li>Using variational autoencoders to learn variations in data (Rudd and Wild, 2018)</li>
</ul>

<h2 id="questions-for-course-staff">Questions for Course Staff</h2>
<ol>
  <li>Does this problem seem tractable, both theoretically and empirically?</li>
  <li>Our idea encompasses two analogous processes, a deterministic pipeline with reconstruction (using an AE), and a random pipeline with new data generation (using a VAE). Do you think either of these is more/less practical, feasible, or interesting to pursue?</li>
  <li>How would you recommend that we get started on this, beyond reading more existing literature on representation learning? We were thinking that perhaps we could try this approach on some smaller examples first (e.g. fixing a dataset and using a few different autoencoder models), and see if any interesting observations result from that, and then dive deeper based on those results. Any advice here would be greatly appreciated!</li>
  <li>Are there any theoretical components that you suggest we focus on, to potentially prove a small theoretical result?</li>
  <li>What empirical results/comparisons would you suggest us to be on the lookout for?</li>
  <li>Any other suggestions?</li>
</ol>

:ET